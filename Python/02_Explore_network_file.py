"""
EXPLORADOR DE RED - Entiende tu archivo GEXF
==============================================

Este script te ayuda a entender quÃ© contiene exactamente
tu archivo de red antes de visualizarlo.
Author: Luis Castellanos - le.castellanos10@uniandes.edu.co

USO:
----
1. Coloca este script en la misma carpeta que tu archivo .gexf
2. Ejecuta: python explore_network.py
3. Lee las sugerencias de thresholds al final
"""

import networkx as nx
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
import os

# ============================================================================
# CONFIGURACIÃ“N
# ============================================================================

NETWORK_FILE = r"C:\Users\User\OneDrive\OneDrive - Universidad de los andes\Global Complexity School\Final project\Bibliography\Joe\ComplexPolicyImpact\out\Complexity_CoCitation_LCC.gexf"

# ============================================================================
# FUNCIONES DE EXPLORACIÃ“N
# ============================================================================

def explore_network_structure(G):
    """
    Explora la estructura bÃ¡sica de la red.
    """
    print("\n" + "="*70)
    print("ESTRUCTURA BÃSICA DE LA RED")
    print("="*70)
    
    print(f"\nðŸ“Š ESTADÃSTICAS GENERALES:")
    print(f"  â€¢ Tipo: {'Dirigida' if G.is_directed() else 'No dirigida'}")
    print(f"  â€¢ NÃºmero de nodos: {G.number_of_nodes():,}")
    print(f"  â€¢ NÃºmero de aristas: {G.number_of_edges():,}")
    print(f"  â€¢ Densidad: {nx.density(G):.6f}")
    print(f"    (0 = sin conexiones, 1 = totalmente conectada)")
    
    # Componentes
    if not G.is_directed():
        components = list(nx.connected_components(G))
        print(f"\nðŸ”— CONECTIVIDAD:")
        print(f"  â€¢ Â¿EstÃ¡ conectada?: {'SÃ­' if nx.is_connected(G) else 'No'}")
        print(f"  â€¢ NÃºmero de componentes: {len(components)}")
        if len(components) > 1:
            sizes = sorted([len(c) for c in components], reverse=True)
            print(f"  â€¢ TamaÃ±o del componente mÃ¡s grande: {sizes[0]:,}")
            print(f"  â€¢ TamaÃ±os de componentes: {sizes[:10]}")


def explore_node_attributes(G):
    """
    Explora los atributos de los nodos.
    """
    print("\n" + "="*70)
    print("ATRIBUTOS DE NODOS")
    print("="*70)
    
    # Obtener lista de todos los atributos
    sample_node = list(G.nodes())[0]
    attributes = list(G.nodes[sample_node].keys())
    
    print(f"\nðŸ“Œ ATRIBUTOS DISPONIBLES:")
    for attr in attributes:
        print(f"  â€¢ {attr}")
    
    # Analizar el atributo 'count' si existe
    if 'count' in attributes:
        counts = [int(G.nodes[n].get('count', 0)) for n in G.nodes()]
        
        print(f"\nðŸ“ˆ DISTRIBUCIÃ“N DE 'count' (citaciones):")
        print(f"  â€¢ MÃ­nimo: {min(counts)}")
        print(f"  â€¢ MÃ¡ximo: {max(counts)}")
        print(f"  â€¢ Promedio: {np.mean(counts):.2f}")
        print(f"  â€¢ Mediana: {np.median(counts):.0f}")
        print(f"  â€¢ DesviaciÃ³n estÃ¡ndar: {np.std(counts):.2f}")
        
        # Percentiles
        print(f"\n  PERCENTILES:")
        for p in [25, 50, 75, 90, 95, 99]:
            value = np.percentile(counts, p)
            print(f"  â€¢ {p}%: {value:.0f}")
        
        # Top nodos mÃ¡s citados
        top_nodes = sorted(
            [(n, G.nodes[n].get('count', 0)) for n in G.nodes()],
            key=lambda x: x[1],
            reverse=True
        )[:10]
        
        print(f"\n  ðŸ† TOP 10 NODOS MÃS CITADOS:")
        for i, (node, count) in enumerate(top_nodes, 1):
            node_short = node.split('/')[-1]
            print(f"  {i:2d}. {node_short}: {count} citaciones")


def explore_edge_attributes(G):
    """
    Explora los atributos de las aristas.
    """
    print("\n" + "="*70)
    print("ATRIBUTOS DE ARISTAS")
    print("="*70)
    
    # Obtener muestra de arista
    sample_edge = list(G.edges(data=True))[0]
    attributes = list(sample_edge[2].keys())
    
    print(f"\nðŸ”— ATRIBUTOS DISPONIBLES:")
    for attr in attributes:
        print(f"  â€¢ {attr}")
    
    # Analizar 'weight' y 'count'
    if 'weight' in attributes:
        weights = [float(data.get('weight', 0)) for u, v, data in G.edges(data=True)]
        
        print(f"\nâš–ï¸  DISTRIBUCIÃ“N DE 'weight' (peso normalizado):")
        print(f"  â€¢ MÃ­nimo: {min(weights):.6f}")
        print(f"  â€¢ MÃ¡ximo: {max(weights):.6f}")
        print(f"  â€¢ Promedio: {np.mean(weights):.6f}")
        print(f"  â€¢ Mediana: {np.median(weights):.6f}")
        
        print(f"\n  PERCENTILES:")
        for p in [25, 50, 75, 90, 95, 99]:
            value = np.percentile(weights, p)
            print(f"  â€¢ {p}%: {value:.6f}")
    
    if 'count' in attributes:
        counts = [int(data.get('count', 0)) for u, v, data in G.edges(data=True)]
        
        print(f"\nðŸ”¢ DISTRIBUCIÃ“N DE 'count' (co-citaciones):")
        print(f"  â€¢ MÃ­nimo: {min(counts)}")
        print(f"  â€¢ MÃ¡ximo: {max(counts)}")
        print(f"  â€¢ Promedio: {np.mean(counts):.2f}")
        print(f"  â€¢ Mediana: {np.median(counts):.0f}")
        
        print(f"\n  PERCENTILES:")
        for p in [25, 50, 75, 90, 95, 99]:
            value = np.percentile(counts, p)
            print(f"  â€¢ {p}%: {value:.0f}")


def explore_degree_distribution(G):
    """
    Analiza la distribuciÃ³n de grados (conexiones).
    """
    print("\n" + "="*70)
    print("DISTRIBUCIÃ“N DE GRADO")
    print("="*70)
    
    degrees = [G.degree(n) for n in G.nodes()]
    
    print(f"\nðŸ“Š ESTADÃSTICAS DE GRADO:")
    print(f"  â€¢ Grado mÃ­nimo: {min(degrees)}")
    print(f"  â€¢ Grado mÃ¡ximo: {max(degrees)}")
    print(f"  â€¢ Grado promedio: {np.mean(degrees):.2f}")
    print(f"  â€¢ Grado mediano: {np.median(degrees):.0f}")
    
    # Nodos mÃ¡s conectados (hubs)
    top_degree_nodes = sorted(
        [(n, G.degree(n)) for n in G.nodes()],
        key=lambda x: x[1],
        reverse=True
    )[:10]
    
    print(f"\n  ðŸŒŸ TOP 10 NODOS MÃS CONECTADOS (HUBS):")
    for i, (node, degree) in enumerate(top_degree_nodes, 1):
        node_short = node.split('/')[-1]
        count = G.nodes[node].get('count', 'N/A')
        print(f"  {i:2d}. {node_short}: {degree} conexiones (citado {count} veces)")


def create_distribution_plots(G, output_dir=r"C:\Users\User\OneDrive\OneDrive - Universidad de los andes\Global Complexity School\Final project\Images"):
    """
    Crea grÃ¡ficos de las distribuciones.
    """
    print("\n" + "="*70)
    print("CREANDO GRÃFICOS DE DISTRIBUCIÃ“N")
    print("="*70)
    
    os.makedirs(output_dir, exist_ok=True)
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # 1. DistribuciÃ³n de grados
    ax1 = axes[0, 0]
    degrees = [G.degree(n) for n in G.nodes()]
    ax1.hist(degrees, bins=50, edgecolor='black', alpha=0.7)
    ax1.set_xlabel('Grade (number of connections)', fontsize=10)
    ax1.set_ylabel('Frequency', fontsize=10)
    ax1.set_title('Degree Distribution', fontweight='bold')
    ax1.set_yscale('log')
    
    # 2. DistribuciÃ³n de citaciones (node count)
    ax2 = axes[0, 1]
    counts = [int(G.nodes[n].get('count', 0)) for n in G.nodes()]
    ax2.hist(counts, bins=50, edgecolor='black', alpha=0.7, color='orange')
    ax2.set_xlabel('Number of citations', fontsize=10)
    ax2.set_ylabel('Frequency', fontsize=10)
    ax2.set_title('Citation Degree', fontweight='bold')
    ax2.set_yscale('log')
    
    # 3. DistribuciÃ³n de pesos de aristas
    ax3 = axes[1, 0]
    weights = [float(data.get('weight', 0)) for u, v, data in G.edges(data=True)]
    ax3.hist(weights, bins=50, edgecolor='black', alpha=0.7, color='green')
    ax3.set_xlabel('Weight (similarity)', fontsize=10)
    ax3.set_ylabel('Frequency', fontsize=10)
    ax3.set_title('Edge Weight Distribution', fontweight='bold')
    
    # 4. DistribuciÃ³n de co-citaciones
    ax4 = axes[1, 1]
    cocitations = [int(data.get('count', 0)) for u, v, data in G.edges(data=True)]
    ax4.hist(cocitations, bins=50, edgecolor='black', alpha=0.7, color='red')
    ax4.set_xlabel('Number of co-citations', fontsize=10)
    ax4.set_ylabel('Frequency', fontsize=10)
    ax4.set_title('Distribution of Co-citations', fontweight='bold')
    ax4.set_yscale('log')
    
    plt.tight_layout()
    
    output_path = os.path.join(output_dir, "distributions_analysis.png")
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"  âœ“ GrÃ¡ficos guardados en: {output_path}")
    plt.close()


def suggest_thresholds(G):
    """
    Sugiere thresholds Ã³ptimos basados en los datos.
    """
    print("\n" + "="*70)
    print("SUGERENCIAS DE THRESHOLDS")
    print("="*70)
    
    weights = [float(data.get('weight', 0)) for u, v, data in G.edges(data=True)]
    counts = [int(data.get('count', 0)) for u, v, data in G.edges(data=True)]
    
    print("\nðŸ’¡ THRESHOLDS SUGERIDOS PARA FILTRADO:")
    print("\n  BASADOS EN PESO (weight):")
    
    for p in [50, 75, 90, 95, 99]:
        value = np.percentile(weights, p)
        remaining = sum(1 for w in weights if w >= value)
        percentage = (remaining / len(weights)) * 100
        print(f"  â€¢ Percentil {p}% = {value:.4f}")
        print(f"    â†’ MantendrÃ­a {remaining:,} aristas ({percentage:.1f}%)")
    
    print("\n  BASADOS EN CO-CITACIONES (count):")
    for p in [50, 75, 90, 95, 99]:
        value = np.percentile(counts, p)
        remaining = sum(1 for c in counts if c >= value)
        percentage = (remaining / len(counts)) * 100
        print(f"  â€¢ Percentil {p}% = {value:.0f} co-citaciones")
        print(f"    â†’ MantendrÃ­a {remaining:,} aristas ({percentage:.1f}%)")
    
    print("\n  ðŸ’¡ RECOMENDACIÃ“N:")
    print("  Para una visualizaciÃ³n clara con comunidades visibles:")
    weight_75 = np.percentile(weights, 75)
    print(f"  â€¢ Usa weight_threshold = {weight_75:.3f} (percentil 75)")
    print(f"  â€¢ O min_cocitations = 5-10")
    print(f"  â€¢ Y min_node_count = 10-20")


# ============================================================================
# MAIN
# ============================================================================

def main():
    print("="*70)
    print("EXPLORADOR DE RED DE CO-CITACIÃ“N")
    print("="*70)
    
    if not os.path.exists(NETWORK_FILE):
        print(f"\nâœ— ERROR: Archivo no encontrado: {NETWORK_FILE}")
        print("  Coloca el archivo .gexf en la misma carpeta que este script")
        return
    
    print(f"\nðŸ“‚ Cargando: {NETWORK_FILE}")
    G = nx.read_gexf(NETWORK_FILE)
    print(f"âœ“ Red cargada exitosamente")
    
    # Explorar estructura
    explore_network_structure(G)
    
    # Explorar nodos
    explore_node_attributes(G)
    
    # Explorar aristas
    explore_edge_attributes(G)
    
    # DistribuciÃ³n de grados
    explore_degree_distribution(G)
    
    # Crear grÃ¡ficos
    create_distribution_plots(G)
    
    # Sugerir thresholds
    suggest_thresholds(G)
    
    print("\n" + "="*70)
    print("âœ“ EXPLORACIÃ“N COMPLETADA")
    print("="*70)
    print("\nAhora puedes usar estos datos para configurar")
    print("el script de visualizaciÃ³n avanzada")


if __name__ == "__main__":
    main()